{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet_pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = './data'\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "filenames = sorted(os.listdir(DATA_FOLDER))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 гривня (зразка 2006 р)\n",
      "1 гривня (зразка 2006 р, зворотнiй бiк)\n",
      "2 гривнi (зразка 2004 р)\n",
      "2 гривнi (зразка 2004 р, зворотнiй бiк)\n",
      "5 гривень (зразка 2004 р)\n",
      "5 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "10 гривень (зразка 2004 р)\n",
      "10 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "20 гривень (зразка 2003 р)\n",
      "20 гривень (зразка 2003 р, зворотнiй бiк)\n",
      "50 гривень (зразка 2004 р)\n",
      "50 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "100 гривень (зразка 2005 р)\n",
      "100 гривень (зразка 2005 р, зворотнiй бiк)\n",
      "200 гривень (зразка 2007 р)\n",
      "200 гривень (зразка 2007 р, зворотнiй бiк)\n",
      "500 гривень (зразка 2006 р)\n",
      "500 гривень (зразка 2006 р, зворотнiй бiк)\n",
      "1000 гривень (зразка 2019 р)\n",
      "1000 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "500 гривень (зразка 2015 р)\n",
      "500 гривень (зразка 2015 р, зворотнiй бiк)\n",
      "100 гривень (зразка 2014 р)\n",
      "100 гривень (зразка 2014 р, зворотнiй бiк)\n",
      "20 гривень (зразка 2018 р)\n",
      "20 гривень (зразка 2018 р, зворотнiй бiк)\n",
      "50 гривень (зразка 2019 р)\n",
      "50 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "200 гривень (зразка 2019 р)\n",
      "200 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "100 доларів\n",
      "100 доларів (зворотнiй бiк)\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "# Show labels of every class\n",
    "with open(os.path.join(DATA_FOLDER, 'labels.txt'), \"r\") as f:\n",
    "    classes_text = f.read()\n",
    "classes = classes_text.split('\\n')\n",
    "print(classes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-1a ./data/01-1a/tf-1565952427481.png\n"
     ]
    }
   ],
   "source": [
    "# Gathering paths of every image in dataset.\n",
    "data = []\n",
    "\n",
    "filenames = [fname for fname in filenames if fname != 'labels.txt']\n",
    "for fname in filenames:\n",
    "    images = glob.glob(os.path.join(DATA_FOLDER, fname, '*.png'))\n",
    "    images += glob.glob(os.path.join(DATA_FOLDER, fname, '*.jpg'))\n",
    "    images += glob.glob(os.path.join(DATA_FOLDER, fname, '*.jpeg'))\n",
    "    data.append((fname, images))\n",
    "\n",
    "print(data[0][0], data[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting all the images into train, dev, test sets.\n",
    "\n",
    "train_dir = './train'\n",
    "dev_dir = './dev'\n",
    "test_dir = './test'\n",
    "random.seed(42)\n",
    "\n",
    "if not os.path.isdir(train_dir) or not os.path.isdir(dev_dir) or not os.path.isdir(test_dir):\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(dev_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    for name, images in data:\n",
    "        os.makedirs(os.path.join(train_dir, name))\n",
    "        os.makedirs(os.path.join(dev_dir, name))\n",
    "        os.makedirs(os.path.join(test_dir, name))\n",
    "        \n",
    "        train_end = int(0.8 * len(images))\n",
    "        dev_end = int(0.9 * len(images))\n",
    "        \n",
    "        random.shuffle(images)\n",
    "        \n",
    "        train = images[:train_end]\n",
    "        dev = images[train_end:dev_end]\n",
    "        test = images[dev_end:]\n",
    "        \n",
    "        # Copy images into corresponding directories.\n",
    "        for image_dir, images_in_dir in zip([train_dir, dev_dir, test_dir], [train, dev, test]):\n",
    "            for image in images_in_dir:\n",
    "                dst = os.path.join(os.path.join(image_dir, name), os.path.basename(image))\n",
    "                shutil.copyfile(image, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3, 30, 18,  9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py:440: UserWarning: torch.gels is deprecated in favour of torch.lstsq and will be removed in the next release. Please use torch.lstsq instead.\n",
      "  res = torch.gels(B, A)[0]\n"
     ]
    }
   ],
   "source": [
    "transf = transforms.Compose([transforms.Resize((224, 224)), transforms.RandomRotation(20), \n",
    "                             transforms.RandomPerspective(), transforms.ToTensor()])\n",
    "\n",
    "# Creating datasets for every folder.\n",
    "train_folder = ImageFolder(root=train_dir, transform=transf)\n",
    "dev_folder = ImageFolder(root=dev_dir, transform=transf)\n",
    "test_folder = ImageFolder(root=test_dir, transform=transf)\n",
    "\n",
    "# Creating loaders for every dataset.\n",
    "train_loader = DataLoader(train_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(dev_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Showing example of coded labels.\n",
    "images, labels = iter(train_loader).next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple convolution neural network (given by pytorch tutorial)\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet from zero to hero\n",
    "\n",
    "efficientnet = efficientnet_pytorch.EfficientNet.from_name('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained EfficientNet as feature extractor + couple of Fully Connected Layer\n",
    "\n",
    "class TransferedEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferedEfficientNet, self).__init__()\n",
    "        self.feature_extractor = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        self.fc1 = nn.Linear(1280 * 7 * 7, 600)\n",
    "        self.fc2 = nn.Linear(600, 33)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor.extract_features(x)\n",
    "        x = x.view(-1, 1280 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/checkpoints/efficientnet-b0-355c32eb.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = TransferedEfficientNet()  # Choose your fighter.\n",
    "model.to(device)  # For GPU\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py:440: UserWarning: torch.gels is deprecated in favour of torch.lstsq and will be removed in the next release. Please use torch.lstsq instead.\n",
      "  res = torch.gels(B, A)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.195304\n",
      "[1,   400] loss: 0.085889\n",
      "[1,   600] loss: 0.090332\n",
      "[1,   800] loss: 0.108014\n",
      "[1,  1000] loss: 0.137762\n",
      "[2,   200] loss: 0.060981\n",
      "[2,   400] loss: 0.080803\n",
      "[2,   600] loss: 0.080575\n",
      "[2,   800] loss: 0.041115\n",
      "[2,  1000] loss: 0.045977\n",
      "[3,   200] loss: 0.064417\n",
      "[3,   400] loss: 0.118629\n",
      "[3,   600] loss: 0.048417\n",
      "[3,   800] loss: 0.053681\n",
      "[3,  1000] loss: 0.023506\n",
      "[4,   200] loss: 0.068049\n",
      "[4,   400] loss: 0.068625\n",
      "[4,   600] loss: 0.053555\n",
      "[4,   800] loss: 0.053583\n",
      "[4,  1000] loss: 0.037105\n",
      "[5,   200] loss: 0.055722\n",
      "[5,   400] loss: 0.049288\n",
      "[5,   600] loss: 0.045770\n",
      "[5,   800] loss: 0.058304\n",
      "[5,  1000] loss: 0.090076\n",
      "[6,   200] loss: 0.030096\n",
      "[6,   400] loss: 0.042557\n",
      "[6,   600] loss: 0.042707\n",
      "[6,   800] loss: 0.027201\n",
      "[6,  1000] loss: 0.021277\n",
      "[7,   200] loss: 0.065125\n",
      "[7,   400] loss: 0.034381\n",
      "[7,   600] loss: 0.039413\n",
      "[7,   800] loss: 0.072828\n",
      "[7,  1000] loss: 0.045965\n",
      "[8,   200] loss: 0.075963\n",
      "[8,   400] loss: 0.027129\n",
      "[8,   600] loss: 0.028814\n",
      "[8,   800] loss: 0.020491\n",
      "[8,  1000] loss: 0.018249\n",
      "[9,   200] loss: 0.050597\n",
      "[9,   400] loss: 0.089303\n",
      "[9,   600] loss: 0.035905\n",
      "[9,   800] loss: 0.020045\n",
      "[9,  1000] loss: 0.029450\n",
      "[10,   200] loss: 0.019343\n",
      "[10,   400] loss: 0.018350\n",
      "[10,   600] loss: 0.035581\n",
      "[10,   800] loss: 0.028466\n",
      "[10,  1000] loss: 0.022712\n",
      "[11,   200] loss: 0.029457\n",
      "[11,   400] loss: 0.054774\n",
      "[11,   600] loss: 0.048159\n",
      "[11,   800] loss: 0.041117\n",
      "[11,  1000] loss: 0.030727\n",
      "[12,   200] loss: 0.027980\n",
      "[12,   400] loss: 0.076533\n",
      "[12,   600] loss: 0.036254\n",
      "[12,   800] loss: 0.027411\n",
      "[12,  1000] loss: 0.013451\n",
      "[13,   200] loss: 0.033644\n",
      "[13,   400] loss: 0.026526\n",
      "[13,   600] loss: 0.028413\n",
      "[13,   800] loss: 0.039479\n",
      "[13,  1000] loss: 0.028140\n",
      "[14,   200] loss: 0.024832\n",
      "[14,   400] loss: 0.048422\n",
      "[14,   600] loss: 0.025477\n",
      "[14,   800] loss: 0.018105\n",
      "[14,  1000] loss: 0.014367\n",
      "[15,   200] loss: 0.051762\n",
      "[15,   400] loss: 0.022190\n",
      "[15,   600] loss: 0.030961\n",
      "[15,   800] loss: 0.039243\n",
      "[15,  1000] loss: 0.025903\n",
      "[16,   200] loss: 0.041277\n",
      "[16,   400] loss: 0.028516\n",
      "[16,   600] loss: 0.025962\n",
      "[16,   800] loss: 0.057454\n",
      "[16,  1000] loss: 0.042086\n",
      "[17,   200] loss: 0.010546\n",
      "[17,   400] loss: 0.004053\n",
      "[17,   600] loss: 0.036031\n",
      "[17,   800] loss: 0.027807\n",
      "[17,  1000] loss: 0.031863\n",
      "[18,   200] loss: 0.035876\n",
      "[18,   400] loss: 0.013650\n",
      "[18,   600] loss: 0.021589\n",
      "[18,   800] loss: 0.023214\n",
      "[18,  1000] loss: 0.023462\n",
      "[19,   200] loss: 0.028350\n",
      "[19,   400] loss: 0.020511\n",
      "[19,   600] loss: 0.024654\n",
      "[19,   800] loss: 0.025667\n",
      "[19,  1000] loss: 0.021702\n",
      "[20,   200] loss: 0.013986\n",
      "[20,   400] loss: 0.009870\n",
      "[20,   600] loss: 0.056648\n",
      "[20,   800] loss: 0.085734\n",
      "[20,  1000] loss: 0.033814\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './trained_models'\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "str_time = time.strftime(\"%Y-%m-%d_%H:%M_model.pth\", time.gmtime())\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_PATH, str_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransferedEfficientNet()\n",
    "model.to(device)  # For GPU\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, str_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev images: 96 %\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in dev_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # For GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on the dev images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of                    1 гривня (зразка 2006 р) : 84 %\n",
      "Accuracy of     1 гривня (зразка 2006 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                    2 гривнi (зразка 2004 р) : 100 %\n",
      "Accuracy of     2 гривнi (зразка 2004 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                   5 гривень (зразка 2004 р) : 100 %\n",
      "Accuracy of    5 гривень (зразка 2004 р, зворотнiй бiк) : 93 %\n",
      "Accuracy of                  10 гривень (зразка 2004 р) : 100 %\n",
      "Accuracy of   10 гривень (зразка 2004 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                  20 гривень (зразка 2003 р) : 93 %\n",
      "Accuracy of   20 гривень (зразка 2003 р, зворотнiй бiк) : 94 %\n",
      "Accuracy of                  50 гривень (зразка 2004 р) : 100 %\n",
      "Accuracy of   50 гривень (зразка 2004 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                 100 гривень (зразка 2005 р) : 100 %\n",
      "Accuracy of  100 гривень (зразка 2005 р, зворотнiй бiк) : 81 %\n",
      "Accuracy of                 200 гривень (зразка 2007 р) : 100 %\n",
      "Accuracy of  200 гривень (зразка 2007 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                 500 гривень (зразка 2006 р) : 100 %\n",
      "Accuracy of  500 гривень (зразка 2006 р, зворотнiй бiк) : 94 %\n",
      "Accuracy of                1000 гривень (зразка 2019 р) : 94 %\n",
      "Accuracy of 1000 гривень (зразка 2019 р, зворотнiй бiк) : 93 %\n",
      "Accuracy of                 500 гривень (зразка 2015 р) : 100 %\n",
      "Accuracy of  500 гривень (зразка 2015 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                 100 гривень (зразка 2014 р) : 100 %\n",
      "Accuracy of  100 гривень (зразка 2014 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                  20 гривень (зразка 2018 р) : 100 %\n",
      "Accuracy of   20 гривень (зразка 2018 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                  50 гривень (зразка 2019 р) : 100 %\n",
      "Accuracy of   50 гривень (зразка 2019 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                 200 гривень (зразка 2019 р) : 100 %\n",
      "Accuracy of  200 гривень (зразка 2019 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                                 100 доларів : 80 %\n",
      "Accuracy of                 100 доларів (зворотнiй бiк) : 75 %\n",
      "Accuracy of                                           ? : 92 %\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy for each class\n",
    "\n",
    "class_correct = [0.0 for i in range(33)]\n",
    "class_total = [0.0 for i in range(33)]\n",
    "with torch.no_grad():\n",
    "    for data in dev_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # For GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(BATCH_SIZE):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(33):\n",
    "    print('Accuracy of %43s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
