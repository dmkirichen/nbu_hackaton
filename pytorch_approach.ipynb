{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = './data'\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "filenames = sorted(os.listdir(DATA_FOLDER))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 гривня (зразка 2006 р)\n",
      "1 гривня (зразка 2006 р, зворотнiй бiк)\n",
      "2 гривнi (зразка 2004 р)\n",
      "2 гривнi (зразка 2004 р, зворотнiй бiк)\n",
      "5 гривень (зразка 2004 р)\n",
      "5 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "10 гривень (зразка 2004 р)\n",
      "10 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "20 гривень (зразка 2003 р)\n",
      "20 гривень (зразка 2003 р, зворотнiй бiк)\n",
      "50 гривень (зразка 2004 р)\n",
      "50 гривень (зразка 2004 р, зворотнiй бiк)\n",
      "100 гривень (зразка 2005 р)\n",
      "100 гривень (зразка 2005 р, зворотнiй бiк)\n",
      "200 гривень (зразка 2007 р)\n",
      "200 гривень (зразка 2007 р, зворотнiй бiк)\n",
      "500 гривень (зразка 2006 р)\n",
      "500 гривень (зразка 2006 р, зворотнiй бiк)\n",
      "1000 гривень (зразка 2019 р)\n",
      "1000 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "500 гривень (зразка 2015 р)\n",
      "500 гривень (зразка 2015 р, зворотнiй бiк)\n",
      "100 гривень (зразка 2014 р)\n",
      "100 гривень (зразка 2014 р, зворотнiй бiк)\n",
      "20 гривень (зразка 2018 р)\n",
      "20 гривень (зразка 2018 р, зворотнiй бiк)\n",
      "50 гривень (зразка 2019 р)\n",
      "50 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "200 гривень (зразка 2019 р)\n",
      "200 гривень (зразка 2019 р, зворотнiй бiк)\n",
      "100 доларів\n",
      "100 доларів (зворотнiй бiк)\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "# Show labels of every class\n",
    "with open(os.path.join(DATA_FOLDER, 'labels.txt'), \"r\") as f:\n",
    "    classes_text = f.read()\n",
    "classes = classes_text.split('\\n')\n",
    "print(classes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-1a ./data/01-1a/tf-1565952427481.png\n"
     ]
    }
   ],
   "source": [
    "# Gathering paths of every image in dataset.\n",
    "data = []\n",
    "\n",
    "filenames = [fname for fname in filenames if fname != 'labels.txt']\n",
    "for fname in filenames:\n",
    "    images = glob.glob(os.path.join(DATA_FOLDER, fname, '*.png'))\n",
    "    images += glob.glob(os.path.join(DATA_FOLDER, fname, '*.jpg'))\n",
    "    images += glob.glob(os.path.join(DATA_FOLDER, fname, '*.jpeg'))\n",
    "    data.append((fname, images))\n",
    "\n",
    "print(data[0][0], data[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting all the images into train, dev, test sets.\n",
    "\n",
    "train_dir = './train'\n",
    "dev_dir = './dev'\n",
    "test_dir = './test'\n",
    "random.seed(42)\n",
    "\n",
    "if not os.path.isdir(train_dir) or not os.path.isdir(dev_dir) or not os.path.isdir(test_dir):\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(dev_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    for name, images in data:\n",
    "        os.makedirs(os.path.join(train_dir, name))\n",
    "        os.makedirs(os.path.join(dev_dir, name))\n",
    "        os.makedirs(os.path.join(test_dir, name))\n",
    "        \n",
    "        train_end = int(0.8 * len(images))\n",
    "        dev_end = int(0.9 * len(images))\n",
    "        \n",
    "        random.shuffle(images)\n",
    "        \n",
    "        train = images[:train_end]\n",
    "        dev = images[train_end:dev_end]\n",
    "        test = images[dev_end:]\n",
    "        \n",
    "        # Copy images into corresponding directories.\n",
    "        for image_dir, images_in_dir in zip([train_dir, dev_dir, test_dir], [train, dev, test]):\n",
    "            for image in images_in_dir:\n",
    "                dst = os.path.join(os.path.join(image_dir, name), os.path.basename(image))\n",
    "                shutil.copyfile(image, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 16, 19, 30])\n"
     ]
    }
   ],
   "source": [
    "transf = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "# Creating datasets for every folder.\n",
    "train_folder = ImageFolder(root=train_dir, transform=transf)\n",
    "dev_folder = ImageFolder(root=dev_dir, transform=transf)\n",
    "test_folder = ImageFolder(root=test_dir, transform=transf)\n",
    "\n",
    "# Creating loaders for every dataset.\n",
    "train_loader = DataLoader(train_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(dev_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_folder, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Showing example of coded labels.\n",
    "images, labels = iter(train_loader).next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple convolution neural network (given by pytorch tutorial)\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 33)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 56 * 56)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline()  # Choose your fighter.\n",
    "model.to(device)  # For GPU\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.330030\n",
      "[1,   400] loss: 0.214296\n",
      "[1,   600] loss: 0.142898\n",
      "[1,   800] loss: 0.113871\n",
      "[1,  1000] loss: 0.089746\n",
      "[2,   200] loss: 0.052259\n",
      "[2,   400] loss: 0.053182\n",
      "[2,   600] loss: 0.046201\n",
      "[2,   800] loss: 0.044364\n",
      "[2,  1000] loss: 0.033695\n",
      "[3,   200] loss: 0.028485\n",
      "[3,   400] loss: 0.035901\n",
      "[3,   600] loss: 0.029149\n",
      "[3,   800] loss: 0.036325\n",
      "[3,  1000] loss: 0.028780\n",
      "[4,   200] loss: 0.022520\n",
      "[4,   400] loss: 0.023575\n",
      "[4,   600] loss: 0.028341\n",
      "[4,   800] loss: 0.018719\n",
      "[4,  1000] loss: 0.033137\n",
      "[5,   200] loss: 0.016662\n",
      "[5,   400] loss: 0.024980\n",
      "[5,   600] loss: 0.018197\n",
      "[5,   800] loss: 0.017332\n",
      "[5,  1000] loss: 0.018291\n",
      "[6,   200] loss: 0.011364\n",
      "[6,   400] loss: 0.018000\n",
      "[6,   600] loss: 0.019468\n",
      "[6,   800] loss: 0.032790\n",
      "[6,  1000] loss: 0.024177\n",
      "[7,   200] loss: 0.015582\n",
      "[7,   400] loss: 0.009650\n",
      "[7,   600] loss: 0.018916\n",
      "[7,   800] loss: 0.010132\n",
      "[7,  1000] loss: 0.008131\n",
      "[8,   200] loss: 0.014259\n",
      "[8,   400] loss: 0.012511\n",
      "[8,   600] loss: 0.005195\n",
      "[8,   800] loss: 0.018456\n",
      "[8,  1000] loss: 0.014759\n",
      "[9,   200] loss: 0.005580\n",
      "[9,   400] loss: 0.025199\n",
      "[9,   600] loss: 0.010979\n",
      "[9,   800] loss: 0.008620\n",
      "[9,  1000] loss: 0.015108\n",
      "[10,   200] loss: 0.004748\n",
      "[10,   400] loss: 0.012246\n",
      "[10,   600] loss: 0.010710\n",
      "[10,   800] loss: 0.004854\n",
      "[10,  1000] loss: 0.010482\n",
      "[11,   200] loss: 0.009613\n",
      "[11,   400] loss: 0.015596\n",
      "[11,   600] loss: 0.011246\n",
      "[11,   800] loss: 0.007458\n",
      "[11,  1000] loss: 0.003046\n",
      "[12,   200] loss: 0.020173\n",
      "[12,   400] loss: 0.012560\n",
      "[12,   600] loss: 0.006622\n",
      "[12,   800] loss: 0.005886\n",
      "[12,  1000] loss: 0.004491\n",
      "[13,   200] loss: 0.004874\n",
      "[13,   400] loss: 0.010045\n",
      "[13,   600] loss: 0.003323\n",
      "[13,   800] loss: 0.021458\n",
      "[13,  1000] loss: 0.005312\n",
      "[14,   200] loss: 0.002297\n",
      "[14,   400] loss: 0.010346\n",
      "[14,   600] loss: 0.007037\n",
      "[14,   800] loss: 0.011243\n",
      "[14,  1000] loss: 0.005447\n",
      "[15,   200] loss: 0.014192\n",
      "[15,   400] loss: 0.003244\n",
      "[15,   600] loss: 0.008080\n",
      "[15,   800] loss: 0.006015\n",
      "[15,  1000] loss: 0.004245\n",
      "[16,   200] loss: 0.010293\n",
      "[16,   400] loss: 0.003706\n",
      "[16,   600] loss: 0.002371\n",
      "[16,   800] loss: 0.004562\n",
      "[16,  1000] loss: 0.005341\n",
      "[17,   200] loss: 0.007254\n",
      "[17,   400] loss: 0.004083\n",
      "[17,   600] loss: 0.015366\n",
      "[17,   800] loss: 0.008187\n",
      "[17,  1000] loss: 0.007684\n",
      "[18,   200] loss: 0.007004\n",
      "[18,   400] loss: 0.007318\n",
      "[18,   600] loss: 0.003402\n",
      "[18,   800] loss: 0.001578\n",
      "[18,  1000] loss: 0.002831\n",
      "[19,   200] loss: 0.005621\n",
      "[19,   400] loss: 0.006208\n",
      "[19,   600] loss: 0.002122\n",
      "[19,   800] loss: 0.002380\n",
      "[19,  1000] loss: 0.013263\n",
      "[20,   200] loss: 0.007780\n",
      "[20,   400] loss: 0.006935\n",
      "[20,   600] loss: 0.004342\n",
      "[20,   800] loss: 0.002747\n",
      "[20,  1000] loss: 0.003622\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './trained_models'\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "str_time = time.strftime(\"%Y-%m-%d_%H:%M_model.pth\", time.gmtime())\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_PATH, str_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Baseline()\n",
    "model.to(device)  # For GPU\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, str_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dev images: 93 %\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in dev_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # For GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on the dev images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of                    1 гривня (зразка 2006 р) : 92 %\n",
      "Accuracy of     1 гривня (зразка 2006 р, зворотнiй бiк) : 85 %\n",
      "Accuracy of                    2 гривнi (зразка 2004 р) : 100 %\n",
      "Accuracy of     2 гривнi (зразка 2004 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                   5 гривень (зразка 2004 р) : 100 %\n",
      "Accuracy of    5 гривень (зразка 2004 р, зворотнiй бiк) : 93 %\n",
      "Accuracy of                  10 гривень (зразка 2004 р) : 93 %\n",
      "Accuracy of   10 гривень (зразка 2004 р, зворотнiй бiк) : 93 %\n",
      "Accuracy of                  20 гривень (зразка 2003 р) : 87 %\n",
      "Accuracy of   20 гривень (зразка 2003 р, зворотнiй бiк) : 82 %\n",
      "Accuracy of                  50 гривень (зразка 2004 р) : 94 %\n",
      "Accuracy of   50 гривень (зразка 2004 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                 100 гривень (зразка 2005 р) : 91 %\n",
      "Accuracy of  100 гривень (зразка 2005 р, зворотнiй бiк) : 81 %\n",
      "Accuracy of                 200 гривень (зразка 2007 р) : 93 %\n",
      "Accuracy of  200 гривень (зразка 2007 р, зворотнiй бiк) : 94 %\n",
      "Accuracy of                 500 гривень (зразка 2006 р) : 89 %\n",
      "Accuracy of  500 гривень (зразка 2006 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                1000 гривень (зразка 2019 р) : 94 %\n",
      "Accuracy of 1000 гривень (зразка 2019 р, зворотнiй бiк) : 93 %\n",
      "Accuracy of                 500 гривень (зразка 2015 р) : 92 %\n",
      "Accuracy of  500 гривень (зразка 2015 р, зворотнiй бiк) : 94 %\n",
      "Accuracy of                 100 гривень (зразка 2014 р) : 100 %\n",
      "Accuracy of  100 гривень (зразка 2014 р, зворотнiй бiк) : 78 %\n",
      "Accuracy of                  20 гривень (зразка 2018 р) : 91 %\n",
      "Accuracy of   20 гривень (зразка 2018 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                  50 гривень (зразка 2019 р) : 100 %\n",
      "Accuracy of   50 гривень (зразка 2019 р, зворотнiй бiк) : 97 %\n",
      "Accuracy of                 200 гривень (зразка 2019 р) : 91 %\n",
      "Accuracy of  200 гривень (зразка 2019 р, зворотнiй бiк) : 100 %\n",
      "Accuracy of                                 100 доларів : 80 %\n",
      "Accuracy of                 100 доларів (зворотнiй бiк) : 100 %\n",
      "Accuracy of                                           ? : 82 %\n"
     ]
    }
   ],
   "source": [
    "# Testing accuracy for each class\n",
    "\n",
    "class_correct = [0.0 for i in range(33)]\n",
    "class_total = [0.0 for i in range(33)]\n",
    "with torch.no_grad():\n",
    "    for data in dev_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # For GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(BATCH_SIZE):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(33):\n",
    "    print('Accuracy of %43s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
